{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "data_root = './data/initial'\n",
    "data_generated = './data/generated'\n",
    "train_dir = './data/train'\n",
    "val_dir = './data/val'\n",
    "test_dir = './data/initial/test'\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(os.path.join(data_generated, 'train'), train_transforms)\n",
    "val_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, loss, dataloader, device):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            preds = model(inputs)\n",
    "            loss_value = loss(preds, labels)\n",
    "            preds_class = preds.argmax(dim=1)\n",
    "            running_loss += loss_value.item()\n",
    "            running_acc += (preds_class == labels.data).float().mean()\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = running_acc / len(dataloader)\n",
    "    if was_training:\n",
    "        model.train()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler, num_epochs, eval_every_nth_batch):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n",
    "\n",
    "        dataloader = train_dataloader\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        batch_id = 0\n",
    "        n_samples_passed = 0\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            scheduler.step()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            preds = model(inputs)\n",
    "            loss_value = loss(preds, labels)\n",
    "            preds_class = preds.argmax(dim=1)\n",
    "\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss_value.item()\n",
    "            running_acc += (preds_class == labels.data).float().mean()\n",
    "            batch_id += 1\n",
    "            if batch_id % eval_every_nth_batch == 0:\n",
    "                train_loss = running_loss / eval_every_nth_batch\n",
    "                train_acc = running_acc / eval_every_nth_batch\n",
    "                val_loss, val_acc = validate_model(model, loss, val_dataloader, device)\n",
    "                print('Train loss: {:.4f} Train acc: {:.4f}'.format(train_loss, train_acc), flush=True)\n",
    "                print('>>> Val loss: {:.4f} Val acc: {:.4f}'.format(val_loss, val_acc), flush=True)\n",
    "                running_loss = 0\n",
    "                running_acc = 0\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.__head = models.resnet18(pretrained=True)\n",
    "        for param in self.__head.parameters():\n",
    "            param.requires_grad = False\n",
    "        #for param in self.__head.layer4[1].parameters():\n",
    "        #    param.requires_grad = True\n",
    "        #self.__head.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "        \n",
    "        self.__bottom = torch.nn.Sequential()\n",
    "        #self.__bottom.add_module(\"linear_1_dropout\", torch.nn.Dropout(p=0.1))\n",
    "        self.__bottom.add_module(\"linear_1\", torch.nn.Linear(self.__head.fc.in_features, 2))\n",
    "        \n",
    "        self.__head.fc = self.__bottom\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.__head.forward(x)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, amsgrad=True, weight_decay=1e-6)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100500, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61affdf2c0d94fae85e1bef335d67b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.8472 Train acc: 0.5625\n",
      ">>> Val loss: 0.7485 Val acc: 0.4414\n",
      "Train loss: 0.6670 Train acc: 0.5625\n",
      ">>> Val loss: 0.6936 Val acc: 0.5534\n",
      "Train loss: 0.6713 Train acc: 0.6250\n",
      ">>> Val loss: 0.6803 Val acc: 0.5625\n",
      "Train loss: 0.6787 Train acc: 0.6094\n",
      ">>> Val loss: 0.6787 Val acc: 0.5599\n",
      "Train loss: 0.6663 Train acc: 0.5781\n",
      ">>> Val loss: 0.6673 Val acc: 0.5716\n",
      "Train loss: 0.5403 Train acc: 0.7500\n",
      ">>> Val loss: 0.6461 Val acc: 0.6276\n",
      "Train loss: 0.5949 Train acc: 0.6094\n",
      ">>> Val loss: 0.6301 Val acc: 0.6497\n",
      "Train loss: 0.5761 Train acc: 0.7031\n",
      ">>> Val loss: 0.6110 Val acc: 0.6758\n",
      "Train loss: 0.5264 Train acc: 0.7812\n",
      ">>> Val loss: 0.6010 Val acc: 0.6836\n",
      "Train loss: 0.5360 Train acc: 0.7344\n",
      ">>> Val loss: 0.5771 Val acc: 0.7057\n",
      "Train loss: 0.5110 Train acc: 0.7656\n",
      ">>> Val loss: 0.5585 Val acc: 0.7487\n",
      "Train loss: 0.5004 Train acc: 0.7969\n",
      ">>> Val loss: 0.5433 Val acc: 0.7643\n",
      "Train loss: 0.4612 Train acc: 0.8125\n",
      ">>> Val loss: 0.5332 Val acc: 0.7760\n",
      "Train loss: 0.4817 Train acc: 0.8281\n",
      ">>> Val loss: 0.5253 Val acc: 0.7865\n",
      "Train loss: 0.3942 Train acc: 0.8906\n",
      ">>> Val loss: 0.5221 Val acc: 0.7682\n",
      "Train loss: 0.4406 Train acc: 0.8750\n",
      ">>> Val loss: 0.5201 Val acc: 0.7734\n",
      "Train loss: 0.3364 Train acc: 0.9531\n",
      ">>> Val loss: 0.5202 Val acc: 0.7656\n",
      "Train loss: 0.3643 Train acc: 0.9219\n",
      ">>> Val loss: 0.5253 Val acc: 0.7357\n",
      "Train loss: 0.3367 Train acc: 0.9375\n",
      ">>> Val loss: 0.5386 Val acc: 0.7083\n",
      "Train loss: 0.3934 Train acc: 0.8281\n",
      ">>> Val loss: 0.5440 Val acc: 0.6641\n",
      "Train loss: 0.3603 Train acc: 0.9062\n",
      ">>> Val loss: 0.5355 Val acc: 0.6836\n",
      "Train loss: 0.3493 Train acc: 0.9219\n",
      ">>> Val loss: 0.5242 Val acc: 0.7161\n",
      "Train loss: 0.3954 Train acc: 0.8438\n",
      ">>> Val loss: 0.4963 Val acc: 0.7773\n",
      "Train loss: 0.3768 Train acc: 0.8750\n",
      ">>> Val loss: 0.4732 Val acc: 0.8060\n",
      "Train loss: 0.3440 Train acc: 0.9219\n",
      ">>> Val loss: 0.4582 Val acc: 0.8555\n",
      "Train loss: 0.3185 Train acc: 0.8750\n",
      ">>> Val loss: 0.4559 Val acc: 0.8385\n",
      "Train loss: 0.3415 Train acc: 0.8750\n",
      ">>> Val loss: 0.4550 Val acc: 0.8372\n",
      "Train loss: 0.3129 Train acc: 0.9062\n",
      ">>> Val loss: 0.4524 Val acc: 0.8307\n",
      "Train loss: 0.2963 Train acc: 0.8906\n",
      ">>> Val loss: 0.4487 Val acc: 0.8398\n",
      "Train loss: 0.2560 Train acc: 0.9531\n",
      ">>> Val loss: 0.4463 Val acc: 0.8398\n",
      "Train loss: 0.3035 Train acc: 0.9219\n",
      ">>> Val loss: 0.4474 Val acc: 0.8320\n",
      "Train loss: 0.3517 Train acc: 0.9062\n",
      ">>> Val loss: 0.4472 Val acc: 0.8411\n",
      "Train loss: 0.2983 Train acc: 0.9219\n",
      ">>> Val loss: 0.4471 Val acc: 0.8307\n",
      "Train loss: 0.2808 Train acc: 0.9062\n",
      ">>> Val loss: 0.4441 Val acc: 0.8516\n",
      "Train loss: 0.3284 Train acc: 0.8594\n",
      ">>> Val loss: 0.4462 Val acc: 0.8594\n",
      "Train loss: 0.2846 Train acc: 0.9062\n",
      ">>> Val loss: 0.4523 Val acc: 0.8372\n",
      "Train loss: 0.2910 Train acc: 0.8906\n",
      ">>> Val loss: 0.4566 Val acc: 0.8190\n",
      "Train loss: 0.3039 Train acc: 0.8906\n",
      ">>> Val loss: 0.4544 Val acc: 0.8229\n",
      "Train loss: 0.3015 Train acc: 0.8750\n",
      ">>> Val loss: 0.4496 Val acc: 0.8529\n",
      "Train loss: 0.2334 Train acc: 0.9688\n",
      ">>> Val loss: 0.4467 Val acc: 0.8555\n",
      "Train loss: 0.1979 Train acc: 0.9844\n",
      ">>> Val loss: 0.4465 Val acc: 0.8542\n",
      "Train loss: 0.2277 Train acc: 0.9688\n",
      ">>> Val loss: 0.4519 Val acc: 0.8151\n",
      "Train loss: 0.2305 Train acc: 0.9688\n",
      ">>> Val loss: 0.4573 Val acc: 0.8255\n",
      "Train loss: 0.3005 Train acc: 0.9062\n",
      ">>> Val loss: 0.4563 Val acc: 0.8255\n",
      "Train loss: 0.2509 Train acc: 0.8906\n",
      ">>> Val loss: 0.4509 Val acc: 0.8190\n",
      "Train loss: 0.2194 Train acc: 0.9531\n",
      ">>> Val loss: 0.4489 Val acc: 0.8503\n",
      "Train loss: 0.2604 Train acc: 0.8906\n",
      ">>> Val loss: 0.4464 Val acc: 0.8516\n",
      "Train loss: 0.3341 Train acc: 0.8594\n",
      ">>> Val loss: 0.4486 Val acc: 0.8620\n",
      "Train loss: 0.2444 Train acc: 0.9375\n",
      ">>> Val loss: 0.4525 Val acc: 0.8268\n",
      "Train loss: 0.2327 Train acc: 0.9375\n",
      ">>> Val loss: 0.4563 Val acc: 0.8190\n",
      "Train loss: 0.2209 Train acc: 0.9688\n",
      ">>> Val loss: 0.4596 Val acc: 0.8190\n",
      "Train loss: 0.2661 Train acc: 0.9219\n",
      ">>> Val loss: 0.4569 Val acc: 0.8151\n",
      "Train loss: 0.2131 Train acc: 0.9531\n",
      ">>> Val loss: 0.4518 Val acc: 0.8346\n",
      "Train loss: 0.2077 Train acc: 0.9531\n",
      ">>> Val loss: 0.4499 Val acc: 0.8503\n",
      "Train loss: 0.2233 Train acc: 0.9688\n",
      ">>> Val loss: 0.4509 Val acc: 0.8581\n",
      "Train loss: 0.2058 Train acc: 0.9688\n",
      ">>> Val loss: 0.4513 Val acc: 0.8372\n",
      "Train loss: 0.2015 Train acc: 0.9688\n",
      ">>> Val loss: 0.4525 Val acc: 0.8581\n",
      "Train loss: 0.1978 Train acc: 0.9844\n",
      ">>> Val loss: 0.4501 Val acc: 0.8581\n",
      "Train loss: 0.1792 Train acc: 0.9688\n",
      ">>> Val loss: 0.4509 Val acc: 0.8581\n",
      "Train loss: 0.2005 Train acc: 0.9688\n",
      ">>> Val loss: 0.4501 Val acc: 0.8581\n",
      "Train loss: 0.1668 Train acc: 0.9844\n",
      ">>> Val loss: 0.4539 Val acc: 0.8268\n",
      "Train loss: 0.2638 Train acc: 0.8750\n",
      ">>> Val loss: 0.4529 Val acc: 0.8424\n",
      "Train loss: 0.2087 Train acc: 0.9688\n",
      ">>> Val loss: 0.4493 Val acc: 0.8581\n",
      "Train loss: 0.1693 Train acc: 1.0000\n",
      ">>> Val loss: 0.4495 Val acc: 0.8268\n",
      "Train loss: 0.1560 Train acc: 1.0000\n",
      ">>> Val loss: 0.4534 Val acc: 0.8203\n",
      "Train loss: 0.1700 Train acc: 0.9688\n",
      ">>> Val loss: 0.4626 Val acc: 0.7917\n",
      "Train loss: 0.2409 Train acc: 0.9062\n",
      ">>> Val loss: 0.4620 Val acc: 0.7669\n",
      "Train loss: 0.1657 Train acc: 1.0000\n",
      ">>> Val loss: 0.4613 Val acc: 0.7852\n",
      "Train loss: 0.2860 Train acc: 0.9062\n",
      ">>> Val loss: 0.4561 Val acc: 0.8021\n",
      "Train loss: 0.1945 Train acc: 0.9531\n",
      ">>> Val loss: 0.4462 Val acc: 0.8398\n",
      "Train loss: 0.1711 Train acc: 0.9844\n",
      ">>> Val loss: 0.4488 Val acc: 0.8503\n",
      "Train loss: 0.1776 Train acc: 0.9844\n",
      ">>> Val loss: 0.4536 Val acc: 0.8307\n",
      "Train loss: 0.2416 Train acc: 0.9062\n",
      ">>> Val loss: 0.4545 Val acc: 0.8307\n",
      "Train loss: 0.1986 Train acc: 0.9531\n",
      ">>> Val loss: 0.4507 Val acc: 0.8424\n",
      "Train loss: 0.1569 Train acc: 0.9844\n",
      ">>> Val loss: 0.4493 Val acc: 0.8438\n",
      "Train loss: 0.1294 Train acc: 1.0000\n",
      ">>> Val loss: 0.4452 Val acc: 0.8398\n",
      "Train loss: 0.1631 Train acc: 1.0000\n",
      ">>> Val loss: 0.4476 Val acc: 0.8438\n",
      "Train loss: 0.1780 Train acc: 0.9844\n",
      ">>> Val loss: 0.4486 Val acc: 0.8477\n",
      "Train loss: 0.1328 Train acc: 1.0000\n",
      ">>> Val loss: 0.4498 Val acc: 0.8477\n",
      "Train loss: 0.1459 Train acc: 0.9844\n",
      ">>> Val loss: 0.4484 Val acc: 0.8438\n",
      "Train loss: 0.1754 Train acc: 0.9688\n",
      ">>> Val loss: 0.4482 Val acc: 0.8398\n",
      "Train loss: 0.1332 Train acc: 1.0000\n",
      ">>> Val loss: 0.4513 Val acc: 0.8359\n",
      "Train loss: 0.2033 Train acc: 0.9688\n",
      ">>> Val loss: 0.4523 Val acc: 0.8503\n",
      "Train loss: 0.1689 Train acc: 0.9688\n",
      ">>> Val loss: 0.4556 Val acc: 0.8464\n",
      "Train loss: 0.1413 Train acc: 1.0000\n",
      ">>> Val loss: 0.4590 Val acc: 0.8268\n",
      "Train loss: 0.1558 Train acc: 0.9844\n",
      ">>> Val loss: 0.4648 Val acc: 0.7956\n",
      "Train loss: 0.1680 Train acc: 0.9375\n",
      ">>> Val loss: 0.4653 Val acc: 0.7917\n",
      "Train loss: 0.1423 Train acc: 0.9844\n",
      ">>> Val loss: 0.4637 Val acc: 0.8034\n",
      "Train loss: 0.1770 Train acc: 0.9531\n",
      ">>> Val loss: 0.4594 Val acc: 0.8190\n",
      "Train loss: 0.1198 Train acc: 1.0000\n",
      ">>> Val loss: 0.4573 Val acc: 0.8385\n",
      "Train loss: 0.1620 Train acc: 0.9688\n",
      ">>> Val loss: 0.4553 Val acc: 0.8464\n",
      "Train loss: 0.1317 Train acc: 0.9844\n",
      ">>> Val loss: 0.4572 Val acc: 0.8398\n",
      "Train loss: 0.1351 Train acc: 0.9844\n",
      ">>> Val loss: 0.4564 Val acc: 0.8424\n",
      "Train loss: 0.1312 Train acc: 1.0000\n",
      ">>> Val loss: 0.4580 Val acc: 0.8424\n",
      "Train loss: 0.1083 Train acc: 1.0000\n",
      ">>> Val loss: 0.4602 Val acc: 0.8268\n",
      "Train loss: 0.1300 Train acc: 0.9844\n",
      ">>> Val loss: 0.4622 Val acc: 0.8268\n",
      "Train loss: 0.1247 Train acc: 0.9844\n",
      ">>> Val loss: 0.4610 Val acc: 0.8229\n",
      "Train loss: 0.1502 Train acc: 1.0000\n",
      ">>> Val loss: 0.4563 Val acc: 0.8464\n",
      "Train loss: 0.1664 Train acc: 0.9688\n",
      ">>> Val loss: 0.4505 Val acc: 0.8503\n",
      "Train loss: 0.1295 Train acc: 0.9844\n",
      ">>> Val loss: 0.4447 Val acc: 0.8359\n",
      "Train loss: 0.1585 Train acc: 0.9844\n",
      ">>> Val loss: 0.4433 Val acc: 0.8398\n",
      "Train loss: 0.1523 Train acc: 0.9688\n",
      ">>> Val loss: 0.4458 Val acc: 0.8294\n",
      "Train loss: 0.1547 Train acc: 0.9844\n",
      ">>> Val loss: 0.4466 Val acc: 0.8216\n",
      "Train loss: 0.1260 Train acc: 0.9844\n",
      ">>> Val loss: 0.4444 Val acc: 0.8216\n",
      "Train loss: 0.0993 Train acc: 1.0000\n",
      ">>> Val loss: 0.4454 Val acc: 0.8320\n",
      "Train loss: 0.1187 Train acc: 0.9844\n",
      ">>> Val loss: 0.4424 Val acc: 0.8320\n",
      "Train loss: 0.1244 Train acc: 1.0000\n",
      ">>> Val loss: 0.4415 Val acc: 0.8359\n",
      "Train loss: 0.1500 Train acc: 0.9688\n",
      ">>> Val loss: 0.4416 Val acc: 0.8398\n",
      "Train loss: 0.1234 Train acc: 0.9844\n",
      ">>> Val loss: 0.4412 Val acc: 0.8398\n",
      "Train loss: 0.1697 Train acc: 0.9375\n",
      ">>> Val loss: 0.4428 Val acc: 0.8398\n",
      "Train loss: 0.1683 Train acc: 0.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Val loss: 0.4415 Val acc: 0.8438\n",
      "Train loss: 0.2024 Train acc: 0.9375\n",
      ">>> Val loss: 0.4427 Val acc: 0.8398\n",
      "Train loss: 0.1234 Train acc: 1.0000\n",
      ">>> Val loss: 0.4458 Val acc: 0.8359\n",
      "Train loss: 0.1459 Train acc: 0.9844\n",
      ">>> Val loss: 0.4503 Val acc: 0.8320\n",
      "Train loss: 0.1064 Train acc: 1.0000\n",
      ">>> Val loss: 0.4557 Val acc: 0.8229\n",
      "Train loss: 0.1364 Train acc: 1.0000\n",
      ">>> Val loss: 0.4645 Val acc: 0.7917\n",
      "Train loss: 0.1700 Train acc: 0.9531\n",
      ">>> Val loss: 0.4662 Val acc: 0.7878\n",
      "Train loss: 0.1217 Train acc: 0.9688\n",
      ">>> Val loss: 0.4568 Val acc: 0.8086\n",
      "Train loss: 0.1650 Train acc: 0.9844\n",
      ">>> Val loss: 0.4475 Val acc: 0.8320\n",
      "Train loss: 0.1063 Train acc: 1.0000\n",
      ">>> Val loss: 0.4428 Val acc: 0.8438\n",
      "Train loss: 0.1131 Train acc: 0.9844\n",
      ">>> Val loss: 0.4393 Val acc: 0.8477\n",
      "Train loss: 0.1455 Train acc: 0.9688\n",
      ">>> Val loss: 0.4373 Val acc: 0.8516\n",
      "Train loss: 0.1078 Train acc: 1.0000\n",
      ">>> Val loss: 0.4383 Val acc: 0.8424\n",
      "Train loss: 0.1652 Train acc: 0.9375\n",
      ">>> Val loss: 0.4363 Val acc: 0.8464\n",
      "Train loss: 0.0977 Train acc: 1.0000\n",
      ">>> Val loss: 0.4331 Val acc: 0.8451\n",
      "Train loss: 0.0948 Train acc: 1.0000\n",
      ">>> Val loss: 0.4318 Val acc: 0.8633\n",
      "Train loss: 0.1025 Train acc: 1.0000\n",
      ">>> Val loss: 0.4322 Val acc: 0.8516\n",
      "Train loss: 0.1241 Train acc: 0.9531\n",
      ">>> Val loss: 0.4328 Val acc: 0.8516\n",
      "Train loss: 0.1235 Train acc: 0.9844\n",
      ">>> Val loss: 0.4343 Val acc: 0.8477\n",
      "Train loss: 0.1004 Train acc: 0.9844\n",
      ">>> Val loss: 0.4431 Val acc: 0.8242\n",
      "Train loss: 0.1060 Train acc: 1.0000\n",
      ">>> Val loss: 0.4490 Val acc: 0.8047\n",
      "Train loss: 0.1187 Train acc: 1.0000\n",
      ">>> Val loss: 0.4532 Val acc: 0.8073\n",
      "Train loss: 0.1067 Train acc: 0.9844\n",
      ">>> Val loss: 0.4558 Val acc: 0.8034\n",
      "Train loss: 0.0761 Train acc: 1.0000\n",
      ">>> Val loss: 0.4583 Val acc: 0.7956\n",
      "Train loss: 0.0788 Train acc: 1.0000\n",
      ">>> Val loss: 0.4615 Val acc: 0.7956\n",
      "Train loss: 0.1086 Train acc: 1.0000\n",
      ">>> Val loss: 0.4590 Val acc: 0.7956\n",
      "Train loss: 0.1716 Train acc: 0.9531\n",
      ">>> Val loss: 0.4480 Val acc: 0.8047\n",
      "Train loss: 0.0663 Train acc: 1.0000\n",
      ">>> Val loss: 0.4399 Val acc: 0.8203\n",
      "Train loss: 0.0873 Train acc: 1.0000\n",
      ">>> Val loss: 0.4340 Val acc: 0.8477\n",
      "Train loss: 0.1109 Train acc: 0.9844\n",
      ">>> Val loss: 0.4296 Val acc: 0.8555\n",
      "Train loss: 0.1062 Train acc: 0.9844\n",
      ">>> Val loss: 0.4277 Val acc: 0.8477\n",
      "Train loss: 0.1147 Train acc: 1.0000\n",
      ">>> Val loss: 0.4267 Val acc: 0.8672\n",
      "Train loss: 0.1427 Train acc: 0.9688\n",
      ">>> Val loss: 0.4247 Val acc: 0.8672\n",
      "Train loss: 0.0993 Train acc: 0.9844\n",
      ">>> Val loss: 0.4242 Val acc: 0.8711\n",
      "Train loss: 0.0951 Train acc: 0.9844\n",
      ">>> Val loss: 0.4250 Val acc: 0.8555\n",
      "Train loss: 0.0961 Train acc: 0.9844\n",
      ">>> Val loss: 0.4272 Val acc: 0.8516\n",
      "Train loss: 0.0926 Train acc: 1.0000\n",
      ">>> Val loss: 0.4329 Val acc: 0.8203\n",
      "Train loss: 0.1168 Train acc: 0.9844\n",
      ">>> Val loss: 0.4384 Val acc: 0.8164\n",
      "Train loss: 0.1002 Train acc: 0.9688\n",
      ">>> Val loss: 0.4427 Val acc: 0.8047\n",
      "Train loss: 0.0973 Train acc: 0.9688\n",
      ">>> Val loss: 0.4439 Val acc: 0.8047\n",
      "Train loss: 0.0734 Train acc: 1.0000\n",
      ">>> Val loss: 0.4454 Val acc: 0.8047\n",
      "Train loss: 0.1002 Train acc: 1.0000\n",
      ">>> Val loss: 0.4470 Val acc: 0.8008\n",
      "Train loss: 0.0834 Train acc: 1.0000\n",
      ">>> Val loss: 0.4467 Val acc: 0.7930\n",
      "Train loss: 0.1346 Train acc: 0.9375\n",
      ">>> Val loss: 0.4407 Val acc: 0.8125\n",
      "Train loss: 0.0748 Train acc: 1.0000\n",
      ">>> Val loss: 0.4375 Val acc: 0.8164\n",
      "Train loss: 0.1212 Train acc: 0.9844\n",
      ">>> Val loss: 0.4337 Val acc: 0.8203\n",
      "Train loss: 0.0896 Train acc: 1.0000\n",
      ">>> Val loss: 0.4288 Val acc: 0.8477\n",
      "Train loss: 0.1926 Train acc: 0.9531\n",
      ">>> Val loss: 0.4255 Val acc: 0.8594\n",
      "Train loss: 0.0994 Train acc: 1.0000\n",
      ">>> Val loss: 0.4245 Val acc: 0.8646\n",
      "Train loss: 0.1326 Train acc: 0.9688\n",
      ">>> Val loss: 0.4283 Val acc: 0.8503\n",
      "Train loss: 0.0747 Train acc: 1.0000\n",
      ">>> Val loss: 0.4295 Val acc: 0.8464\n",
      "Train loss: 0.0868 Train acc: 1.0000\n",
      ">>> Val loss: 0.4290 Val acc: 0.8424\n",
      "Train loss: 0.0899 Train acc: 0.9844\n",
      ">>> Val loss: 0.4274 Val acc: 0.8464\n",
      "Train loss: 0.0636 Train acc: 1.0000\n",
      ">>> Val loss: 0.4259 Val acc: 0.8646\n",
      "Train loss: 0.0914 Train acc: 0.9844\n",
      ">>> Val loss: 0.4248 Val acc: 0.8568\n",
      "Train loss: 0.0686 Train acc: 0.9844\n",
      ">>> Val loss: 0.4247 Val acc: 0.8633\n",
      "Train loss: 0.0730 Train acc: 1.0000\n",
      ">>> Val loss: 0.4248 Val acc: 0.8672\n",
      "Train loss: 0.1384 Train acc: 0.9688\n",
      ">>> Val loss: 0.4289 Val acc: 0.8516\n",
      "Train loss: 0.0679 Train acc: 1.0000\n",
      ">>> Val loss: 0.4402 Val acc: 0.8203\n",
      "Train loss: 0.0816 Train acc: 1.0000\n",
      ">>> Val loss: 0.4521 Val acc: 0.7930\n",
      "Train loss: 0.1173 Train acc: 0.9531\n",
      ">>> Val loss: 0.4659 Val acc: 0.7839\n",
      "Train loss: 0.0887 Train acc: 1.0000\n",
      ">>> Val loss: 0.4872 Val acc: 0.7526\n",
      "Train loss: 0.0677 Train acc: 1.0000\n",
      ">>> Val loss: 0.4999 Val acc: 0.7448\n",
      "Train loss: 0.0881 Train acc: 0.9844\n",
      ">>> Val loss: 0.5053 Val acc: 0.7409\n",
      "Train loss: 0.0996 Train acc: 0.9688\n",
      ">>> Val loss: 0.5088 Val acc: 0.7370\n",
      "Train loss: 0.0867 Train acc: 0.9844\n",
      ">>> Val loss: 0.5038 Val acc: 0.7448\n",
      "Train loss: 0.2091 Train acc: 0.9219\n",
      ">>> Val loss: 0.4863 Val acc: 0.7565\n",
      "Train loss: 0.1383 Train acc: 0.9688\n",
      ">>> Val loss: 0.4554 Val acc: 0.7891\n",
      "Train loss: 0.0682 Train acc: 1.0000\n",
      ">>> Val loss: 0.4326 Val acc: 0.8281\n",
      "Train loss: 0.0818 Train acc: 1.0000\n",
      ">>> Val loss: 0.4216 Val acc: 0.8594\n",
      "Train loss: 0.0582 Train acc: 1.0000\n",
      ">>> Val loss: 0.4219 Val acc: 0.8724\n",
      "Train loss: 0.0805 Train acc: 1.0000\n",
      ">>> Val loss: 0.4333 Val acc: 0.8398\n",
      "Train loss: 0.0780 Train acc: 0.9844\n",
      ">>> Val loss: 0.4412 Val acc: 0.8151\n",
      "Train loss: 0.1193 Train acc: 0.9688\n",
      ">>> Val loss: 0.4528 Val acc: 0.7969\n",
      "Train loss: 0.1421 Train acc: 0.9688\n",
      ">>> Val loss: 0.4538 Val acc: 0.7969\n",
      "Train loss: 0.1137 Train acc: 0.9844\n",
      ">>> Val loss: 0.4508 Val acc: 0.8008\n",
      "Train loss: 0.1045 Train acc: 0.9688\n",
      ">>> Val loss: 0.4413 Val acc: 0.8255\n",
      "Train loss: 0.0930 Train acc: 0.9844\n",
      ">>> Val loss: 0.4285 Val acc: 0.8503\n",
      "Train loss: 0.0569 Train acc: 1.0000\n",
      ">>> Val loss: 0.4230 Val acc: 0.8685\n",
      "Train loss: 0.0801 Train acc: 0.9844\n",
      ">>> Val loss: 0.4266 Val acc: 0.8594\n",
      "Train loss: 0.0761 Train acc: 1.0000\n",
      ">>> Val loss: 0.4341 Val acc: 0.8398\n",
      "Train loss: 0.0745 Train acc: 0.9844\n",
      ">>> Val loss: 0.4473 Val acc: 0.8125\n",
      "Train loss: 0.0628 Train acc: 1.0000\n",
      ">>> Val loss: 0.4612 Val acc: 0.7891\n",
      "Train loss: 0.0957 Train acc: 1.0000\n",
      ">>> Val loss: 0.4823 Val acc: 0.7539\n",
      "Train loss: 0.0690 Train acc: 1.0000\n",
      ">>> Val loss: 0.4949 Val acc: 0.7526\n",
      "Train loss: 0.0997 Train acc: 1.0000\n",
      ">>> Val loss: 0.4949 Val acc: 0.7526\n",
      "Train loss: 0.0744 Train acc: 0.9844\n",
      ">>> Val loss: 0.4874 Val acc: 0.7526\n",
      "Train loss: 0.0847 Train acc: 1.0000\n",
      ">>> Val loss: 0.4786 Val acc: 0.7578\n",
      "Train loss: 0.1180 Train acc: 1.0000\n",
      ">>> Val loss: 0.4606 Val acc: 0.7891\n",
      "Train loss: 0.0759 Train acc: 1.0000\n",
      ">>> Val loss: 0.4477 Val acc: 0.8008\n",
      "Train loss: 0.1048 Train acc: 0.9844\n",
      ">>> Val loss: 0.4399 Val acc: 0.8203\n",
      "Train loss: 0.0896 Train acc: 0.9844\n",
      ">>> Val loss: 0.4353 Val acc: 0.8359\n",
      "Train loss: 0.0657 Train acc: 1.0000\n",
      ">>> Val loss: 0.4397 Val acc: 0.8281\n",
      "Train loss: 0.1229 Train acc: 0.9531\n",
      ">>> Val loss: 0.4315 Val acc: 0.8438\n",
      "Train loss: 0.0486 Train acc: 1.0000\n",
      ">>> Val loss: 0.4257 Val acc: 0.8555\n",
      "Train loss: 0.0562 Train acc: 1.0000\n",
      ">>> Val loss: 0.4259 Val acc: 0.8594\n",
      "Train loss: 0.0658 Train acc: 1.0000\n",
      ">>> Val loss: 0.4256 Val acc: 0.8529\n",
      "Train loss: 0.0884 Train acc: 1.0000\n",
      ">>> Val loss: 0.4257 Val acc: 0.8607\n",
      "Train loss: 0.0922 Train acc: 0.9844\n",
      ">>> Val loss: 0.4287 Val acc: 0.8529\n",
      "Train loss: 0.0968 Train acc: 0.9844\n",
      ">>> Val loss: 0.4286 Val acc: 0.8607\n",
      "Train loss: 0.1749 Train acc: 0.9219\n",
      ">>> Val loss: 0.4295 Val acc: 0.8646\n",
      "Train loss: 0.0736 Train acc: 1.0000\n",
      ">>> Val loss: 0.4275 Val acc: 0.8607\n",
      "Train loss: 0.0671 Train acc: 1.0000\n",
      ">>> Val loss: 0.4290 Val acc: 0.8411\n",
      "Train loss: 0.0715 Train acc: 0.9844\n",
      ">>> Val loss: 0.4332 Val acc: 0.8516\n",
      "Train loss: 0.0604 Train acc: 1.0000\n",
      ">>> Val loss: 0.4397 Val acc: 0.8281\n",
      "Train loss: 0.0707 Train acc: 0.9844\n",
      ">>> Val loss: 0.4493 Val acc: 0.8047\n",
      "Train loss: 0.0674 Train acc: 1.0000\n",
      ">>> Val loss: 0.4589 Val acc: 0.7891\n",
      "Train loss: 0.0791 Train acc: 1.0000\n",
      ">>> Val loss: 0.4701 Val acc: 0.7812\n",
      "Train loss: 0.0626 Train acc: 1.0000\n",
      ">>> Val loss: 0.4719 Val acc: 0.7773\n",
      "Train loss: 0.1094 Train acc: 0.9688\n",
      ">>> Val loss: 0.4761 Val acc: 0.7656\n",
      "Train loss: 0.0750 Train acc: 0.9844\n",
      ">>> Val loss: 0.4727 Val acc: 0.7695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0954 Train acc: 0.9844\n",
      ">>> Val loss: 0.4766 Val acc: 0.7734\n",
      "Train loss: 0.1121 Train acc: 0.9688\n",
      ">>> Val loss: 0.4710 Val acc: 0.7773\n",
      "Train loss: 0.1046 Train acc: 0.9844\n",
      ">>> Val loss: 0.4527 Val acc: 0.7969\n",
      "Train loss: 0.0671 Train acc: 0.9844\n",
      ">>> Val loss: 0.4362 Val acc: 0.8359\n",
      "Train loss: 0.0785 Train acc: 1.0000\n",
      ">>> Val loss: 0.4268 Val acc: 0.8555\n",
      "Train loss: 0.0799 Train acc: 0.9844\n",
      ">>> Val loss: 0.4243 Val acc: 0.8568\n",
      "Train loss: 0.0845 Train acc: 0.9688\n",
      ">>> Val loss: 0.4233 Val acc: 0.8607\n",
      "Train loss: 0.0874 Train acc: 0.9688\n",
      ">>> Val loss: 0.4228 Val acc: 0.8529\n",
      "Train loss: 0.0503 Train acc: 1.0000\n",
      ">>> Val loss: 0.4251 Val acc: 0.8633\n",
      "Train loss: 0.0828 Train acc: 0.9844\n",
      ">>> Val loss: 0.4237 Val acc: 0.8529\n",
      "Train loss: 0.0751 Train acc: 0.9688\n",
      ">>> Val loss: 0.4227 Val acc: 0.8594\n",
      "Train loss: 0.0618 Train acc: 1.0000\n",
      ">>> Val loss: 0.4303 Val acc: 0.8516\n",
      "Train loss: 0.0760 Train acc: 0.9844\n",
      ">>> Val loss: 0.4360 Val acc: 0.8281\n",
      "Train loss: 0.1041 Train acc: 0.9531\n",
      ">>> Val loss: 0.4508 Val acc: 0.7969\n",
      "Train loss: 0.0840 Train acc: 0.9688\n",
      ">>> Val loss: 0.4679 Val acc: 0.7852\n",
      "Train loss: 0.1025 Train acc: 0.9688\n",
      ">>> Val loss: 0.4869 Val acc: 0.7760\n",
      "Train loss: 0.1054 Train acc: 0.9688\n",
      ">>> Val loss: 0.5009 Val acc: 0.7604\n",
      "Train loss: 0.0939 Train acc: 0.9844\n",
      ">>> Val loss: 0.5087 Val acc: 0.7487\n",
      "Train loss: 0.0837 Train acc: 0.9844\n",
      ">>> Val loss: 0.5242 Val acc: 0.7331\n",
      "Train loss: 0.0838 Train acc: 0.9844\n",
      ">>> Val loss: 0.5360 Val acc: 0.7292\n",
      "Train loss: 0.0800 Train acc: 0.9844\n",
      ">>> Val loss: 0.5289 Val acc: 0.7331\n",
      "Train loss: 0.0871 Train acc: 0.9844\n",
      ">>> Val loss: 0.5155 Val acc: 0.7487\n",
      "Train loss: 0.0517 Train acc: 1.0000\n",
      ">>> Val loss: 0.5079 Val acc: 0.7604\n",
      "Train loss: 0.0807 Train acc: 0.9688\n",
      ">>> Val loss: 0.4939 Val acc: 0.7682\n",
      "Train loss: 0.0943 Train acc: 0.9844\n",
      ">>> Val loss: 0.4834 Val acc: 0.7695\n",
      "Train loss: 0.0518 Train acc: 1.0000\n",
      ">>> Val loss: 0.4669 Val acc: 0.7852\n",
      "Train loss: 0.0655 Train acc: 1.0000\n",
      ">>> Val loss: 0.4536 Val acc: 0.8008\n",
      "Train loss: 0.1138 Train acc: 0.9844\n",
      ">>> Val loss: 0.4386 Val acc: 0.8203\n",
      "Train loss: 0.1088 Train acc: 0.9844\n",
      ">>> Val loss: 0.4295 Val acc: 0.8294\n",
      "Train loss: 0.0996 Train acc: 0.9844\n",
      ">>> Val loss: 0.4271 Val acc: 0.8411\n",
      "Train loss: 0.0904 Train acc: 0.9844\n",
      ">>> Val loss: 0.4266 Val acc: 0.8529\n",
      "Train loss: 0.0523 Train acc: 1.0000\n",
      ">>> Val loss: 0.4286 Val acc: 0.8607\n",
      "Train loss: 0.0681 Train acc: 1.0000\n",
      ">>> Val loss: 0.4320 Val acc: 0.8385\n",
      "Train loss: 0.0742 Train acc: 1.0000\n",
      ">>> Val loss: 0.4318 Val acc: 0.8451\n",
      "Train loss: 0.0750 Train acc: 1.0000\n",
      ">>> Val loss: 0.4313 Val acc: 0.8529\n",
      "Train loss: 0.0525 Train acc: 1.0000\n",
      ">>> Val loss: 0.4332 Val acc: 0.8477\n",
      "Train loss: 0.0565 Train acc: 1.0000\n",
      ">>> Val loss: 0.4409 Val acc: 0.8242\n",
      "Train loss: 0.0410 Train acc: 1.0000\n",
      ">>> Val loss: 0.4495 Val acc: 0.8086\n",
      "Train loss: 0.0505 Train acc: 1.0000\n",
      ">>> Val loss: 0.4574 Val acc: 0.8047\n",
      "Train loss: 0.0607 Train acc: 1.0000\n",
      ">>> Val loss: 0.4648 Val acc: 0.7891\n",
      "Train loss: 0.0563 Train acc: 1.0000\n",
      ">>> Val loss: 0.4672 Val acc: 0.7891\n",
      "Train loss: 0.0505 Train acc: 1.0000\n",
      ">>> Val loss: 0.4640 Val acc: 0.7891\n",
      "Train loss: 0.0849 Train acc: 1.0000\n",
      ">>> Val loss: 0.4675 Val acc: 0.7891\n",
      "Train loss: 0.0890 Train acc: 0.9844\n",
      ">>> Val loss: 0.4608 Val acc: 0.7969\n",
      "Train loss: 0.0619 Train acc: 1.0000\n",
      ">>> Val loss: 0.4487 Val acc: 0.8164\n",
      "Train loss: 0.0527 Train acc: 1.0000\n",
      ">>> Val loss: 0.4369 Val acc: 0.8320\n",
      "Train loss: 0.0656 Train acc: 1.0000\n",
      ">>> Val loss: 0.4359 Val acc: 0.8451\n",
      "Train loss: 0.0677 Train acc: 1.0000\n",
      ">>> Val loss: 0.4338 Val acc: 0.8451\n",
      "Train loss: 0.1137 Train acc: 0.9844\n",
      ">>> Val loss: 0.4294 Val acc: 0.8529\n",
      "Train loss: 0.0524 Train acc: 1.0000\n",
      ">>> Val loss: 0.4330 Val acc: 0.8451\n",
      "Train loss: 0.0359 Train acc: 1.0000\n",
      ">>> Val loss: 0.4378 Val acc: 0.8333\n",
      "Train loss: 0.0838 Train acc: 0.9844\n",
      ">>> Val loss: 0.4403 Val acc: 0.8281\n",
      "Train loss: 0.0974 Train acc: 0.9844\n",
      ">>> Val loss: 0.4494 Val acc: 0.8125\n",
      "Train loss: 0.0796 Train acc: 0.9844\n",
      ">>> Val loss: 0.4633 Val acc: 0.7930\n",
      "Train loss: 0.0576 Train acc: 1.0000\n",
      ">>> Val loss: 0.4834 Val acc: 0.7812\n",
      "Train loss: 0.0535 Train acc: 1.0000\n",
      ">>> Val loss: 0.4960 Val acc: 0.7734\n",
      "Train loss: 0.0510 Train acc: 1.0000\n",
      ">>> Val loss: 0.5024 Val acc: 0.7695\n",
      "Train loss: 0.0995 Train acc: 0.9688\n",
      ">>> Val loss: 0.5004 Val acc: 0.7695\n",
      "Train loss: 0.0767 Train acc: 0.9844\n",
      ">>> Val loss: 0.4940 Val acc: 0.7734\n",
      "Train loss: 0.0791 Train acc: 1.0000\n",
      ">>> Val loss: 0.4796 Val acc: 0.7812\n",
      "Train loss: 0.0499 Train acc: 1.0000\n",
      ">>> Val loss: 0.4654 Val acc: 0.7969\n",
      "Train loss: 0.1042 Train acc: 0.9375\n",
      ">>> Val loss: 0.4515 Val acc: 0.8125\n",
      "Train loss: 0.0733 Train acc: 0.9844\n",
      ">>> Val loss: 0.4398 Val acc: 0.8359\n",
      "Train loss: 0.0849 Train acc: 1.0000\n",
      ">>> Val loss: 0.4312 Val acc: 0.8490\n",
      "Train loss: 0.0487 Train acc: 1.0000\n",
      ">>> Val loss: 0.4309 Val acc: 0.8568\n",
      "Train loss: 0.0563 Train acc: 1.0000\n",
      ">>> Val loss: 0.4286 Val acc: 0.8724\n",
      "Train loss: 0.0751 Train acc: 0.9844\n",
      ">>> Val loss: 0.4308 Val acc: 0.8685\n",
      "Train loss: 0.0502 Train acc: 1.0000\n",
      ">>> Val loss: 0.4319 Val acc: 0.8568\n",
      "Train loss: 0.0525 Train acc: 1.0000\n",
      ">>> Val loss: 0.4317 Val acc: 0.8568\n",
      "Train loss: 0.0839 Train acc: 1.0000\n",
      ">>> Val loss: 0.4307 Val acc: 0.8568\n",
      "Train loss: 0.0679 Train acc: 1.0000\n",
      ">>> Val loss: 0.4300 Val acc: 0.8529\n",
      "Train loss: 0.0397 Train acc: 1.0000\n",
      ">>> Val loss: 0.4339 Val acc: 0.8438\n",
      "Train loss: 0.0492 Train acc: 1.0000\n",
      ">>> Val loss: 0.4473 Val acc: 0.8164\n",
      "Train loss: 0.0477 Train acc: 1.0000\n",
      ">>> Val loss: 0.4591 Val acc: 0.8047\n",
      "Train loss: 0.0586 Train acc: 0.9844\n",
      ">>> Val loss: 0.4735 Val acc: 0.7969\n",
      "Train loss: 0.0492 Train acc: 1.0000\n",
      ">>> Val loss: 0.4961 Val acc: 0.7734\n",
      "Train loss: 0.0801 Train acc: 0.9688\n",
      ">>> Val loss: 0.5095 Val acc: 0.7617\n",
      "Train loss: 0.0487 Train acc: 1.0000\n",
      ">>> Val loss: 0.5083 Val acc: 0.7617\n",
      "Train loss: 0.0678 Train acc: 1.0000\n",
      ">>> Val loss: 0.5124 Val acc: 0.7617\n",
      "Train loss: 0.0516 Train acc: 1.0000\n",
      ">>> Val loss: 0.5129 Val acc: 0.7578\n",
      "Train loss: 0.0557 Train acc: 1.0000\n",
      ">>> Val loss: 0.5159 Val acc: 0.7578\n",
      "Train loss: 0.0409 Train acc: 0.9844\n",
      ">>> Val loss: 0.5332 Val acc: 0.7448\n",
      "Train loss: 0.0469 Train acc: 1.0000\n",
      ">>> Val loss: 0.5476 Val acc: 0.7409\n",
      "Train loss: 0.0980 Train acc: 0.9688\n",
      ">>> Val loss: 0.5539 Val acc: 0.7370\n",
      "Train loss: 0.0360 Train acc: 1.0000\n",
      ">>> Val loss: 0.5352 Val acc: 0.7344\n",
      "Train loss: 0.1411 Train acc: 0.9375\n",
      ">>> Val loss: 0.5146 Val acc: 0.7617\n",
      "Train loss: 0.0721 Train acc: 1.0000\n",
      ">>> Val loss: 0.4848 Val acc: 0.7734\n",
      "Train loss: 0.0537 Train acc: 0.9844\n",
      ">>> Val loss: 0.4696 Val acc: 0.7930\n",
      "Train loss: 0.0575 Train acc: 1.0000\n",
      ">>> Val loss: 0.4577 Val acc: 0.8086\n",
      "Train loss: 0.0839 Train acc: 0.9844\n",
      ">>> Val loss: 0.4414 Val acc: 0.8359\n",
      "Train loss: 0.0655 Train acc: 0.9844\n",
      ">>> Val loss: 0.4319 Val acc: 0.8451\n",
      "Train loss: 0.0752 Train acc: 1.0000\n",
      ">>> Val loss: 0.4321 Val acc: 0.8451\n",
      "Train loss: 0.0502 Train acc: 1.0000\n",
      ">>> Val loss: 0.4353 Val acc: 0.8529\n",
      "Train loss: 0.1799 Train acc: 0.9375\n",
      ">>> Val loss: 0.4379 Val acc: 0.8372\n",
      "Train loss: 0.0584 Train acc: 0.9844\n",
      ">>> Val loss: 0.4499 Val acc: 0.8242\n",
      "Train loss: 0.0515 Train acc: 0.9844\n",
      ">>> Val loss: 0.4589 Val acc: 0.8047\n",
      "Train loss: 0.0755 Train acc: 0.9844\n",
      ">>> Val loss: 0.4705 Val acc: 0.7969\n",
      "Train loss: 0.0860 Train acc: 0.9844\n",
      ">>> Val loss: 0.4844 Val acc: 0.7852\n",
      "Train loss: 0.0306 Train acc: 1.0000\n",
      ">>> Val loss: 0.4922 Val acc: 0.7812\n",
      "Train loss: 0.0399 Train acc: 1.0000\n",
      ">>> Val loss: 0.5000 Val acc: 0.7734\n",
      "Train loss: 0.0465 Train acc: 1.0000\n",
      ">>> Val loss: 0.5035 Val acc: 0.7734\n",
      "Train loss: 0.0479 Train acc: 1.0000\n",
      ">>> Val loss: 0.5054 Val acc: 0.7734\n",
      "Train loss: 0.0499 Train acc: 1.0000\n",
      ">>> Val loss: 0.5023 Val acc: 0.7734\n",
      "Train loss: 0.0324 Train acc: 1.0000\n",
      ">>> Val loss: 0.5004 Val acc: 0.7734\n",
      "Train loss: 0.0546 Train acc: 0.9844\n",
      ">>> Val loss: 0.5028 Val acc: 0.7773\n",
      "Train loss: 0.0491 Train acc: 1.0000\n",
      ">>> Val loss: 0.5145 Val acc: 0.7734\n",
      "Train loss: 0.0603 Train acc: 0.9844\n",
      ">>> Val loss: 0.5256 Val acc: 0.7539\n",
      "Train loss: 0.0639 Train acc: 0.9844\n",
      ">>> Val loss: 0.5187 Val acc: 0.7617\n",
      "Train loss: 0.0584 Train acc: 1.0000\n",
      ">>> Val loss: 0.5160 Val acc: 0.7656\n",
      "Train loss: 0.0658 Train acc: 0.9844\n",
      ">>> Val loss: 0.5076 Val acc: 0.7773\n",
      "Train loss: 0.0791 Train acc: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Val loss: 0.5076 Val acc: 0.7734\n",
      "Train loss: 0.0384 Train acc: 1.0000\n",
      ">>> Val loss: 0.4920 Val acc: 0.7773\n",
      "Train loss: 0.0449 Train acc: 1.0000\n",
      ">>> Val loss: 0.4808 Val acc: 0.7969\n",
      "Train loss: 0.0526 Train acc: 0.9844\n",
      ">>> Val loss: 0.4670 Val acc: 0.8008\n",
      "Train loss: 0.0666 Train acc: 0.9844\n",
      ">>> Val loss: 0.4616 Val acc: 0.8125\n",
      "Train loss: 0.0501 Train acc: 0.9844\n",
      ">>> Val loss: 0.4495 Val acc: 0.8320\n",
      "Train loss: 0.0539 Train acc: 1.0000\n",
      ">>> Val loss: 0.4447 Val acc: 0.8294\n",
      "Train loss: 0.0396 Train acc: 1.0000\n",
      ">>> Val loss: 0.4410 Val acc: 0.8529\n",
      "Train loss: 0.0771 Train acc: 0.9688\n",
      ">>> Val loss: 0.4387 Val acc: 0.8529\n",
      "Train loss: 0.0606 Train acc: 0.9844\n",
      ">>> Val loss: 0.4386 Val acc: 0.8464\n",
      "Train loss: 0.0615 Train acc: 0.9688\n",
      ">>> Val loss: 0.4382 Val acc: 0.8424\n",
      "Train loss: 0.0622 Train acc: 0.9844\n",
      ">>> Val loss: 0.4391 Val acc: 0.8411\n",
      "Train loss: 0.0820 Train acc: 0.9688\n",
      ">>> Val loss: 0.4401 Val acc: 0.8333\n",
      "Train loss: 0.0583 Train acc: 0.9844\n",
      ">>> Val loss: 0.4495 Val acc: 0.8177\n",
      "Train loss: 0.0334 Train acc: 1.0000\n",
      ">>> Val loss: 0.4554 Val acc: 0.8164\n",
      "Train loss: 0.0462 Train acc: 1.0000\n",
      ">>> Val loss: 0.4601 Val acc: 0.8125\n",
      "Train loss: 0.0951 Train acc: 0.9688\n",
      ">>> Val loss: 0.4680 Val acc: 0.8047\n",
      "Train loss: 0.1451 Train acc: 0.9375\n",
      ">>> Val loss: 0.4801 Val acc: 0.7930\n",
      "Train loss: 0.0450 Train acc: 1.0000\n",
      ">>> Val loss: 0.4776 Val acc: 0.7969\n",
      "Train loss: 0.0291 Train acc: 1.0000\n",
      ">>> Val loss: 0.4781 Val acc: 0.7930\n",
      "Train loss: 0.0352 Train acc: 1.0000\n",
      ">>> Val loss: 0.4764 Val acc: 0.7969\n",
      "Train loss: 0.0477 Train acc: 0.9844\n",
      ">>> Val loss: 0.4749 Val acc: 0.8047\n",
      "Train loss: 0.0593 Train acc: 1.0000\n",
      ">>> Val loss: 0.4823 Val acc: 0.7969\n",
      "Train loss: 0.0761 Train acc: 0.9844\n",
      ">>> Val loss: 0.4849 Val acc: 0.7969\n",
      "Train loss: 0.0694 Train acc: 1.0000\n",
      ">>> Val loss: 0.4831 Val acc: 0.7969\n",
      "Train loss: 0.0424 Train acc: 1.0000\n",
      ">>> Val loss: 0.4813 Val acc: 0.7969\n",
      "Train loss: 0.0440 Train acc: 1.0000\n",
      ">>> Val loss: 0.4718 Val acc: 0.8047\n",
      "Train loss: 0.0437 Train acc: 1.0000\n",
      ">>> Val loss: 0.4689 Val acc: 0.8047\n",
      "Train loss: 0.0715 Train acc: 1.0000\n",
      ">>> Val loss: 0.4651 Val acc: 0.8086\n",
      "Train loss: 0.0438 Train acc: 1.0000\n",
      ">>> Val loss: 0.4642 Val acc: 0.8125\n",
      "Train loss: 0.0479 Train acc: 1.0000\n",
      ">>> Val loss: 0.4640 Val acc: 0.8125\n",
      "Train loss: 0.0486 Train acc: 1.0000\n",
      ">>> Val loss: 0.4598 Val acc: 0.8164\n",
      "Train loss: 0.0388 Train acc: 1.0000\n",
      ">>> Val loss: 0.4584 Val acc: 0.8125\n",
      "Train loss: 0.0378 Train acc: 1.0000\n",
      ">>> Val loss: 0.4639 Val acc: 0.8086\n",
      "Train loss: 0.1590 Train acc: 0.9688\n",
      ">>> Val loss: 0.4755 Val acc: 0.8008\n",
      "Train loss: 0.0599 Train acc: 0.9844\n",
      ">>> Val loss: 0.5007 Val acc: 0.7773\n",
      "Train loss: 0.0487 Train acc: 0.9844\n",
      ">>> Val loss: 0.5114 Val acc: 0.7734\n",
      "Train loss: 0.0353 Train acc: 1.0000\n",
      ">>> Val loss: 0.5240 Val acc: 0.7656\n",
      "Train loss: 0.0555 Train acc: 1.0000\n",
      ">>> Val loss: 0.5305 Val acc: 0.7578\n",
      "Train loss: 0.0419 Train acc: 1.0000\n",
      ">>> Val loss: 0.5328 Val acc: 0.7539\n",
      "Train loss: 0.0849 Train acc: 0.9844\n",
      ">>> Val loss: 0.5265 Val acc: 0.7695\n",
      "Train loss: 0.0424 Train acc: 1.0000\n",
      ">>> Val loss: 0.5131 Val acc: 0.7734\n",
      "Train loss: 0.0374 Train acc: 1.0000\n",
      ">>> Val loss: 0.4938 Val acc: 0.7852\n",
      "Train loss: 0.0296 Train acc: 1.0000\n",
      ">>> Val loss: 0.4852 Val acc: 0.7930\n",
      "Train loss: 0.0550 Train acc: 1.0000\n",
      ">>> Val loss: 0.4752 Val acc: 0.8008\n",
      "Train loss: 0.0352 Train acc: 1.0000\n",
      ">>> Val loss: 0.4749 Val acc: 0.7930\n",
      "Train loss: 0.0469 Train acc: 0.9844\n",
      ">>> Val loss: 0.4763 Val acc: 0.7969\n",
      "Train loss: 0.0542 Train acc: 0.9844\n",
      ">>> Val loss: 0.4712 Val acc: 0.8047\n",
      "Train loss: 0.0475 Train acc: 0.9844\n",
      ">>> Val loss: 0.4691 Val acc: 0.8047\n",
      "Train loss: 0.0598 Train acc: 0.9844\n",
      ">>> Val loss: 0.4594 Val acc: 0.8164\n",
      "Train loss: 0.1395 Train acc: 0.9531\n",
      ">>> Val loss: 0.4533 Val acc: 0.8203\n",
      "Train loss: 0.0481 Train acc: 1.0000\n",
      ">>> Val loss: 0.4616 Val acc: 0.8164\n",
      "Train loss: 0.0338 Train acc: 1.0000\n",
      ">>> Val loss: 0.4718 Val acc: 0.8086\n",
      "Train loss: 0.0420 Train acc: 1.0000\n",
      ">>> Val loss: 0.4772 Val acc: 0.8047\n",
      "Train loss: 0.0334 Train acc: 1.0000\n",
      ">>> Val loss: 0.4811 Val acc: 0.7969\n",
      "Train loss: 0.0278 Train acc: 1.0000\n",
      ">>> Val loss: 0.4779 Val acc: 0.7969\n",
      "Train loss: 0.0341 Train acc: 1.0000\n",
      ">>> Val loss: 0.4723 Val acc: 0.8047\n",
      "Train loss: 0.0495 Train acc: 1.0000\n",
      ">>> Val loss: 0.4693 Val acc: 0.8086\n",
      "Train loss: 0.0768 Train acc: 0.9844\n",
      ">>> Val loss: 0.4712 Val acc: 0.8047\n",
      "Train loss: 0.0475 Train acc: 1.0000\n",
      ">>> Val loss: 0.4773 Val acc: 0.8008\n",
      "Train loss: 0.0459 Train acc: 0.9844\n",
      ">>> Val loss: 0.4866 Val acc: 0.7969\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a043cdba6461>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     val_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers)\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_every_nth_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_every_nth_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-99fd43ef2855>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, loss, optimizer, scheduler, num_epochs, eval_every_nth_batch)\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0meval_every_nth_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_acc\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0meval_every_nth_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                 \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train loss: {:.4f} Train acc: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>>> Val loss: {:.4f} Val acc: {:.4f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a3ea624646f6>\u001b[0m in \u001b[0;36mvalidate_model\u001b[1;34m(model, loss, dataloader, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mpreds_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mrunning_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "eval_every_nth_batch = 1\n",
    "n_workers = 4\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=n_workers)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=n_workers)\n",
    "\n",
    "train_model(model, loss, optimizer, scheduler, num_epochs=1, eval_every_nth_batch=eval_every_nth_batch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = os.path.basename(self.imgs[index][0])\n",
    "        path = path.split()[0]\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "    \n",
    "test_dataset = ImageFolderWithPaths(test_dir, val_transforms)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ae88dabba0484097ea257b6335d08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_img_paths = []\n",
    "for inputs, labels, paths in tqdm(test_dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        preds = model(inputs)\n",
    "    test_predictions.append(\n",
    "        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n",
    "    test_img_paths.extend(paths)\n",
    "    \n",
    "test_predictions = np.concatenate(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0002</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0003</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0005</th>\n",
       "      <td>dirty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "id         \n",
       "0000  dirty\n",
       "0001  dirty\n",
       "0002  dirty\n",
       "0003  dirty\n",
       "0004  dirty\n",
       "0005  dirty"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.5 else 'cleaned')\n",
    "submission_df['id'] = submission_df['id'].str.replace('test/unknown/', '')\n",
    "submission_df['id'] = submission_df['id'].str.replace('.jpg', '')\n",
    "submission_df.set_index('id', inplace=True)\n",
    "submission_df.head(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:00<00:00, 162.61it/s]\n",
      "100%|| 20/20 [00:00<00:00, 172.42it/s]\n"
     ]
    }
   ],
   "source": [
    "class_names = ['cleaned', 'dirty']\n",
    "\n",
    "for dir_name in [train_dir, val_dir]:\n",
    "    for class_name in class_names:\n",
    "        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n",
    "\n",
    "for class_name in class_names:\n",
    "    source_dir = os.path.join(data_root, 'train', class_name)\n",
    "    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n",
    "        if i % 6 != 0:\n",
    "            dest_dir = os.path.join(train_dir, class_name) \n",
    "        else:\n",
    "            dest_dir = os.path.join(val_dir, class_name)\n",
    "        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def prepare_dirs(root_path):\n",
    "    shutil.rmtree(root_path, ignore_errors=True)\n",
    "    os.makedirs(os.path.join(root_path, 'dirty'))\n",
    "    os.makedirs(os.path.join(root_path, 'clean'))\n",
    "\n",
    "def make_dataset(directory):\n",
    "    ts = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ColorJitter(brightness=0.3, hue=0.25),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(180.0),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.15, 0.15))\n",
    "    ])\n",
    "    return torchvision.datasets.ImageFolder(directory, ts)\n",
    "\n",
    "def make_train_dataset():\n",
    "    return make_dataset(train_dir)\n",
    "\n",
    "def make_val_dataset():\n",
    "    return make_dataset(val_dir)\n",
    "\n",
    "def generate_images(n_amount, dataset_factory, dataset_type, root_path):\n",
    "    path = os.path.join(root_path, dataset_type)\n",
    "    prepare_dirs(path)\n",
    "    name_pattern = '{{:0{}d}}.png'.format(len(str(n_amount)))\n",
    "    class_path = {0: 'clean', 1: 'dirty'}\n",
    "    image_id = 0\n",
    "    while True:\n",
    "        dataset = dataset_factory()\n",
    "        data_iter = iter(dataset)\n",
    "        for image, class_id in data_iter:\n",
    "            if image_id >= n_amount:\n",
    "                return\n",
    "            image_name = name_pattern.format(image_id)\n",
    "            image, class_id = next(data_iter)\n",
    "            image.save(os.path.join(path, class_path[class_id], image_name), 'PNG')\n",
    "            image_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_gen_images_train = 262144\n",
    "n_gen_images_val = 4096\n",
    "\n",
    "generate_images(n_gen_images_train, make_train_dataset, 'train', data_generated)\n",
    "#generate_images(n_gen_images_val, make_val_dataset, 'val', data_generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
